function getRealTarget = function getRealTarget() {
        if (realTarget === undefined) {
            const target = targetCreator();
            validator(target);
            // We copy all properties. We won't use them, but help us avoid Proxy
            // invariant violations
            const properties = Object.getOwnPropertyNames(target);
            for (const property of properties) {
                const descriptor = Object.getOwnPropertyDescriptor(target, property);
                Object.defineProperty(dummyTarget, property, descriptor);
            }
            Object.setPrototypeOf(dummyTarget, Object.getPrototypeOf(target));
            // Using a null prototype seems to tirgger a V8 bug, so we forbid it
            // See: https://github.com/nodejs/node/issues/29730
            if (Object.getPrototypeOf(target) === null) {
                throw new errors_1.HardhatError(errors_list_1.ERRORS.GENERAL.UNSUPPORTED_OPERATION, {
                    operation: "Using lazyFunction or lazyObjec...
function getPragmaAbicoderDirectiveInfo = function getPragmaAbicoderDirectiveInfo(sortedFiles) {
    let directive = "";
    const directivesByImportance = [
        "pragma abicoder v1",
        "pragma experimental ABIEncoderV2",
        "pragma abicoder v2",
    ];
    const filesWithoutPragmaDirectives = new Set();
    const filesWithMostImportantDirective = []; // Every array element has the structure: [ fileName, fileMostImportantDirective ]
    for (const file of sortedFiles) {
        const matches = [
            ...file.content.rawContent.matchAll(PRAGMA_DIRECTIVES_REGEX),
        ];
        if (matches.length === 0) {
            filesWithoutPragmaDirectives.add(file.sourceName);
            continue;
        }
        let fileMostImportantDirective = "";
        for (const groups of matches) {
            const normalizedPragma = removeUnnecessarySpaces(groups[1]);
            // Update the most important pragma directive among all the files
            if (directivesByImportance.indexOf(normalizedPragma) >
    ...
_tmp_15.INVALID_CONFIG = {
            number: 8,
            message: `There's one or more errors in your config file:

%errors%

To learn more about Hardhat's configuration, please go to https://hardhat.org/config/`,
            title: "Invalid Hardhat config",
            description: `You have one or more errors in your config file.

Check the error message for details, or go to the [documentation](https://hardhat.org/config/) to learn more.`,
            shouldBeReported: false,
        }
this._indent(() => {
                    this._logBaseFeePerGas(block);
                    for (let i = 0; i < block.transactions.length; i++) {
                        const tx = block.transactions[i];
                        const txGasUsed = results[i].totalGasSpent;
                        const txTrace = traces[i];
                        const code = codes[i];
                        this._logTxInsideBlock(tx, txTrace, code, txGasUsed, {
                            highlightTxHash: false,
                        });
                        this._logEmptyLineBetweenTransactions(i, block.transactions.length);
                    }
                })
function confirmationPromptWithTimeout = async function confirmationPromptWithTimeout(name, message, timeoutMilliseconds = 10000) {
    try {
        const enquirer = require("enquirer");
        const prompt = new enquirer.prompts.Confirm(createConfirmationPrompt(name, message));
        let timeout;
        const timeoutPromise = new Promise((resolve) => {
            timeout = setTimeout(resolve, timeoutMilliseconds);
        });
        const result = await Promise.race([prompt.run(), timeoutPromise]);
        clearTimeout(timeout);
        if (result === undefined) {
            await prompt.cancel();
        }
        return result;
    }
    catch (e) {
        if (e === "") {
            return undefined;
        }
        // eslint-disable-next-line @nomicfoundation/hardhat-internal-rules/only-hardhat-error
        throw e;
    }
}
function createLazyProxy = function createLazyProxy<ActualT extends GuardT, GuardT extends object>(
  targetCreator: () => ActualT,
  dummyTargetCreator: (getRealTarget: () => ActualT) => GuardT,
  validator: (target: any) => void
): ActualT {
  let realTarget: ActualT | undefined;

  const dummyTarget: ActualT = dummyTargetCreator(getRealTarget) as any;

  function getRealTarget(): ActualT {
    if (realTarget === undefined) {
      const target = targetCreator();
      validator(target);

      // We copy all properties. We won't use them, but help us avoid Proxy
      // invariant violations
      const properties = Object.getOwnPropertyNames(target);
      for (const property of properties) {
        const descriptor = Object.getOwnPropertyDescriptor(target, property)!;
        Object.defineProperty(dummyTarget, property, descriptor);
      }

      Object.setPrototypeOf(dummyTarget, Object.getPrototypeOf(target));

      // Using a null prototype seems to tirgger a V8 bug, so we forbid it
      // See: h...
_tmp_24.description = "There was an error while loading your config file.

The most common source of errors is trying to import the Hardhat Runtime Environment from your config or a file imported from it.
This is not possible, as Hardhat can't be initialized while its config is being defined.

You may also have accidentally imported \`hardhat\` instead of \`hardhat/config\`.

Please make sure your config file is correct.

To learn more about how to access the Hardhat Runtime Environment from different contexts go to https://hardhat.org/hre"
function getPragmaAbicoderDirectiveInfo = function getPragmaAbicoderDirectiveInfo(
  sortedFiles: ResolvedFile[]
): [string, string[], string[]] {
  let directive = "";
  const directivesByImportance = [
    "pragma abicoder v1",
    "pragma experimental ABIEncoderV2",
    "pragma abicoder v2",
  ];
  const filesWithoutPragmaDirectives: Set<string> = new Set();
  const filesWithMostImportantDirective: Array<[string, string]> = []; // Every array element has the structure: [ fileName, fileMostImportantDirective ]

  for (const file of sortedFiles) {
    const matches = [
      ...file.content.rawContent.matchAll(PRAGMA_DIRECTIVES_REGEX),
    ];

    if (matches.length === 0) {
      filesWithoutPragmaDirectives.add(file.sourceName);
      continue;
    }

    let fileMostImportantDirective = "";
    for (const groups of matches) {
      const normalizedPragma = removeUnnecessarySpaces(groups[1]);

      // Update the most important pragma directive among all the files
      if (
        directivesByImportance.indexOf(normali...
_tmp_57.hardforkHistory = new Map([
          [HardforkName.BYZANTIUM, 5067000],
          [HardforkName.CONSTANTINOPLE, 9200000],
          [HardforkName.PETERSBURG, 10255201],
          [HardforkName.ISTANBUL, 14111141],
          [HardforkName.BERLIN, 24770900],
          [HardforkName.LONDON, 26741100],
        ])
function getFileTrueCase = async function getFileTrueCase(
  from: string,
  relativePath: string
): Promise<string> {
  const dirEntries = await readdir(from);

  const parts = relativePath.split(path.sep);
  const nextDirLowerCase = parts[0].toLowerCase();

  for (const dirEntry of dirEntries) {
    if (dirEntry.toLowerCase() === nextDirLowerCase) {
      if (parts.length === 1) {
        return dirEntry;
      }

      return path.join(
        dirEntry,
        await getFileTrueCase(
          path.join(from, dirEntry),
          path.relative(parts[0], relativePath)
        )
      );
    }
  }

  // eslint-disable-next-line @nomicfoundation/hardhat-internal-rules/only-hardhat-error
  throw new FileNotFoundError(path.join(from, relativePath));
}
const jumpType =
      isJump(opcode) && sourceMap.jumpType === JumpType.NOT_JUMP
        ? JumpType.INTERNAL_JUMP
        : sourceMap.jumpType
function resolveHardhatNetworkConfig = function resolveHardhatNetworkConfig(
  hardhatNetworkConfig: HardhatNetworkUserConfig = {}
): HardhatNetworkConfig {
  const clonedDefaultHardhatNetworkParams = cloneDeep(
    defaultHardhatNetworkParams
  );

  const accounts: HardhatNetworkAccountsConfig =
    hardhatNetworkConfig.accounts === undefined
      ? defaultHardhatNetworkHdAccountsConfigParams
      : Array.isArray(hardhatNetworkConfig.accounts)
      ? hardhatNetworkConfig.accounts.map(({ privateKey, balance }) => ({
          privateKey: normalizeHexString(privateKey),
          balance,
        }))
      : {
          ...defaultHardhatNetworkHdAccountsConfigParams,
          ...hardhatNetworkConfig.accounts,
        };

  const forking: HardhatNetworkForkingConfig | undefined =
    hardhatNetworkConfig.forking !== undefined
      ? {
          url: hardhatNetworkConfig.forking.url,
          enabled: hardhatNetworkConfig.forking.enabled ?? true,
          httpHeaders: {},
        }
      : undefined;

  if (forking ...
_tmp_14.LIB_IMPORTED_FROM_THE_CONFIG = {
      number: 9,
      message: `Error while loading Hardhat's configuration.

You probably tried to import the "hardhat" module from your config or a file imported from it.
This is not possible, as Hardhat can't be initialized while its config is being defined.

To learn more about how to access the Hardhat Runtime Environment from different contexts go to https://hardhat.org/hre`,
      title: "Failed to load config file",
      description: `There was an error while loading your config file.

The most common source of errors is trying to import the Hardhat Runtime Environment from your config or a file imported from it.
This is not possible, as Hardhat can't be initialized while its config is being defined.

You may also have accidentally imported \`hardhat\` instead of \`hardhat/config\`.

Please make sure your config file is correct.

To learn more about how to access the Hardhat Runtime Environment from different contexts go to https://hardhat.org/hre`,
      shouldBeReporte...
function printStackTrace = function printStackTrace(trace) {
    const withDecodedMessages = trace.map((entry) => entry.type === solidity_stack_trace_1.StackTraceEntryType.REVERT_ERROR
        ? { ...entry, message: entry.message.decodeError() }
        : entry);
    const withHexAddress = withDecodedMessages.map((entry) => "address" in entry
        ? { ...entry, address: (0, ethereumjs_util_1.bufferToHex)(entry.address) }
        : entry);
    const withTextualType = withHexAddress.map((entry) => ({
        ...entry,
        type: solidity_stack_trace_1.StackTraceEntryType[entry.type],
    }));
    const withFlattenedSourceReferences = withTextualType.map((entry) => ({
        ...entry,
        sourceReference: flattenSourceReference(entry.sourceReference),
    }));
    console.log(JSON.stringify(withFlattenedSourceReferences, (key, value) => (typeof value === "bigint" ? value.toString() : value), 2));
}
function getCompletionData = async function getCompletionData() {
    const projectId = getProjectId();
    if (projectId === undefined) {
        return undefined;
    }
    const cachedCompletionData = await getCachedCompletionData(projectId);
    if (cachedCompletionData !== undefined) {
        if (arePreviousMtimesCorrect(cachedCompletionData.mtimes)) {
            return cachedCompletionData.completionData;
        }
    }
    const filesBeforeRequire = Object.keys(require.cache);
    let hre;
    try {
        process.env.TS_NODE_TRANSPILE_ONLY = "1";
        require("../../register");
        hre = global.hre;
    }
    catch {
        return undefined;
    }
    const filesAfterRequire = Object.keys(require.cache);
    const mtimes = getMtimes(filesBeforeRequire, filesAfterRequire);
    const networks = Object.keys(hre.config.networks);
    // we extract the tasks data explicitly to make sure everything
    // is serializable and to avoid saving unnecessary things from the HRE
    const tasks = (0, lan...
public readonly run: RunTaskFunction = async (
    name,
    taskArguments = {},
    subtaskArguments = {},
    callerTaskProfile?: TaskProfile
  ) => {
    const taskDefinition = this.tasks[name];

    log("Running task %s", name);

    if (taskDefinition === undefined) {
      throw new HardhatError(ERRORS.ARGUMENTS.UNRECOGNIZED_TASK, {
        task: name,
      });
    }

    const resolvedTaskArguments = this._resolveValidTaskArguments(
      taskDefinition,
      taskArguments,
      subtaskArguments
    );

    let taskProfile: TaskProfile | undefined;
    if (this.hardhatArguments.flamegraph === true) {
      taskProfile = createTaskProfile(name);

      if (callerTaskProfile !== undefined) {
        callerTaskProfile.children.push(taskProfile);
      } else {
        this.entryTaskProfile = taskProfile;
      }
    }

    try {
      return await this._runTaskDefinition(
        taskDefinition,
        resolvedTaskArguments,
        subtaskArguments,
        taskProfile
    ...
throw new HardhatError(ERRORS.RESOLVER.INVALID_IMPORT_PROTOCOL, {
        from: from.sourceName,
        imported,
        protocol: scheme,
      });
function processContractAstNode = function processContractAstNode(
  file: SourceFile,
  contractNode: any,
  fileIdToSourceFile: Map<number, SourceFile>,
  contractType: ContractType,
  contractIdToContract: Map<number, Contract>,
  contractIdToLinearizedBaseContractIds: Map<number, number[]>,
  contractAbi?: ContractAbi
) {
  const contractLocation = astSrcToSourceLocation(
    contractNode.src,
    fileIdToSourceFile
  )!;

  const contract = new Contract(
    contractNode.name,
    contractType,
    contractLocation
  );

  contractIdToContract.set(contractNode.id, contract);
  contractIdToLinearizedBaseContractIds.set(
    contractNode.id,
    contractNode.linearizedBaseContracts
  );

  file.addContract(contract);

  for (const node of contractNode.nodes) {
    if (node.nodeType === "FunctionDefinition") {
      const functionAbis = contractAbi?.filter(
        (abiEntry) => abiEntry.name === node.name
      );

      processFunctionDefinitionAstNode(
        node,
        fileIdToSourceFile,
        contract,...
function getRpcReceiptOutputsFromLocalBlockExecution = function getRpcReceiptOutputsFromLocalBlockExecution(block, runBlockResult, showTransactionType) {
    const receipts = [];
    let blockLogIndex = 0;
    for (let i = 0; i < runBlockResult.results.length; i += 1) {
        const tx = block.transactions[i];
        const { createdAddress, totalGasSpent } = runBlockResult.results[i];
        const receipt = runBlockResult.receipts[i];
        const logs = receipt.logs.map((log) => {
            const result = getRpcLogOutput(log, tx, block, i, blockLogIndex);
            blockLogIndex += 1;
            return result;
        });
        const rpcReceipt = {
            transactionHash: (0, base_types_1.bufferToRpcData)(tx.hash()),
            transactionIndex: (0, base_types_1.numberToRpcQuantity)(i),
            blockHash: (0, base_types_1.bufferToRpcData)(block.hash()),
            blockNumber: (0, base_types_1.numberToRpcQuantity)(block.header.number),
            from: (0, base_types_1.bufferToRpcData)(tx.getSenderAddress().toBuf...
_tmp_23.description = "There was an error while loading your config file.

The most common source of errors is trying to import the Hardhat Runtime Environment from your config or a file imported from it.
This is not possible, as Hardhat can't be initialized while its config is being defined.

You may also have accidentally imported \`hardhat\` instead of \`hardhat/config\`.

Please make sure your config file is correct.

To learn more about how to access the Hardhat Runtime Environment from different contexts go to https://hardhat.org/hre"
const genesisBlockBaseFeePerGas = (0, hardforks_1.hardforkGte)(hardfork, hardforks_1.HardforkName.LONDON)
                ? initialBaseFeePerGasConfig ??
                    BigInt(default_config_1.HARDHAT_NETWORK_DEFAULT_INITIAL_BASE_FEE_PER_GAS)
                : undefined
(0, config_env_1.subtask)(task_names_1.TASK_FLATTEN_GET_FLATTENED_SOURCE_AND_METADATA, "Returns all contracts and their dependencies flattened. Also return metadata about pragma directives and SPDX licenses")
    .addOptionalParam("files", undefined, undefined, config_env_1.types.any)
    .setAction(async ({ files }, { run }) => {
    const dependencyGraph = await run(task_names_1.TASK_FLATTEN_GET_DEPENDENCY_GRAPH, { files });
    let flattened = "";
    if (dependencyGraph.getResolvedFiles().length === 0) {
        return [flattened, null];
    }
    const packageJson = await (0, packageInfo_1.getPackageJson)();
    flattened += `// Sources flattened with hardhat v${packageJson.version} https://hardhat.org`;
    const sortedFiles = getSortedFiles(dependencyGraph);
    const [licenses, filesWithoutLicenses] = getLicensesInfo(sortedFiles);
    const [pragmaDirective, filesWithoutPragmaDirectives, filesWithDifferentPragmaDirectives,] = getPragmaAbicoderDirectiveInfo(sortedFiles);
    ...
_tmp_23.push((async () => {
                    if (pathToBuildInfo === undefined) {
                        return;
                    }
                    // save debug file
                    const debugFilePath = this._getDebugFilePath(artifactPath);
                    const debugFile = this._createDebugFile(artifactPath, pathToBuildInfo);
                    await fs_extra_1.default.writeJSON(debugFilePath, debugFile, {
                        spaces: 2,
                    });
                })())
ReadOnlyValidUnknownTypeTransactionPrototype._processSignature = function () {
  throw new InternalError(
    "`_processSignature` is not implemented in ReadOnlyValidUnknownTypeTransaction"
  );
}
function applyContractsInheritance = function applyContractsInheritance(contractIdToContract, contractIdToLinearizedBaseContractIds) {
    for (const [cid, contract] of contractIdToContract.entries()) {
        const inheritanceIds = contractIdToLinearizedBaseContractIds.get(cid);
        for (const baseId of inheritanceIds) {
            const baseContract = contractIdToContract.get(baseId);
            if (baseContract === undefined) {
                // This list includes interface, which we don't model
                continue;
            }
            contract.addNextLinearizedBaseContract(baseContract);
        }
    }
}
function applyProviderWrappers = function applyProviderWrappers(
  provider: EIP1193Provider,
  netConfig: Partial<NetworkConfig>,
  extenders: ProviderExtender[]
): EIP1193Provider {
  // These dependencies are lazy-loaded because they are really big.
  const LocalAccountsProvider = importProvider<
    typeof import("./accounts"),
    "LocalAccountsProvider"
  >("./accounts", "LocalAccountsProvider");
  const HDWalletProvider = importProvider<
    typeof import("./accounts"),
    "HDWalletProvider"
  >("./accounts", "HDWalletProvider");
  const FixedSenderProvider = importProvider<
    typeof import("./accounts"),
    "FixedSenderProvider"
  >("./accounts", "FixedSenderProvider");
  const AutomaticSenderProvider = importProvider<
    typeof import("./accounts"),
    "AutomaticSenderProvider"
  >("./accounts", "AutomaticSenderProvider");

  const AutomaticGasProvider = importProvider<
    typeof import("./gas-providers"),
    "AutomaticGasProvider"
  >("./gas-providers", "AutomaticGasProvider");
  const FixedGasPro...
_tmp_15.TS_NODE_NOT_INSTALLED = {
            number: 13,
            message: `Your Hardhat project uses typescript, but ts-node is not installed.

Please run: npm install --save-dev ts-node`,
            title: "ts-node not installed",
            description: `You are running a Hardhat project that uses typescript, but you haven't installed ts-node.

Please run this and try again: \`npm install --save-dev ts-node\``,
            shouldBeReported: false,
        }
function analyzeModuleNotFoundError = function analyzeModuleNotFoundError(error: any, configPath: string) {
  const stackTraceParser =
    require("stacktrace-parser") as typeof StackTraceParserT;

  if (error.code !== "MODULE_NOT_FOUND") {
    return;
  }
  const stackTrace = stackTraceParser.parse(error.stack);
  const throwingFile = stackTrace
    .filter((x) => x.file !== null)
    .map((x) => x.file!)
    // ignore frames related to source map support
    .filter((x) => !x.includes(path.join("@cspotcode", "source-map-support")))
    .find((x) => path.isAbsolute(x));

  if (throwingFile === null || throwingFile === undefined) {
    return;
  }

  // if the error comes from the config file, we ignore it because we know it's
  // a direct import that's missing
  if (throwingFile === configPath) {
    return;
  }

  const packageJsonPath = findClosestPackageJson(throwingFile);

  if (packageJsonPath === null) {
    return;
  }

  const packageJson = fsExtra.readJsonSync(packageJsonPath);
  const peerDependencies: { [na...
(0, config_env_1.subtask)(task_names_1.TASK_COMPILE_SOLIDITY_GET_COMPILATION_JOBS)
    .addParam("dependencyGraph", undefined, undefined, config_env_1.types.any)
    .addOptionalParam("solidityFilesCache", undefined, undefined, config_env_1.types.any)
    .setAction(async ({ dependencyGraph, solidityFilesCache, }, { run }) => {
    const connectedComponents = dependencyGraph.getConnectedComponents();
    log(`The dependency graph was divided in '${connectedComponents.length}' connected components`);
    const compilationJobsCreationResults = await Promise.all(connectedComponents.map((graph) => (0, compilation_job_1.createCompilationJobsFromConnectedComponent)(graph, (file) => run(task_names_1.TASK_COMPILE_SOLIDITY_GET_COMPILATION_JOB_FOR_FILE, {
        file,
        dependencyGraph,
        solidityFilesCache,
    }))));
    let jobs = [];
    let errors = [];
    for (const result of compilationJobsCreationResults) {
        jobs = jobs.concat(result.jobs);
        errors = errors...
function checkIsAccessListEIP2930ValuesArray = function checkIsAccessListEIP2930ValuesArray(
  values: unknown
): asserts values is AccessListEIP2930ValuesArray {
  if (!Array.isArray(values)) {
    throw new InvalidArgumentsError(
      `Invalid deserialized tx. Expected a Buffer[], but got '${values as any}'`
    );
  }

  if (values.length !== 8 && values.length !== 11) {
    throw new InvalidArgumentsError(
      "Invalid EIP-2930 transaction. Only expecting 8 values (for unsigned tx) or 11 values (for signed tx)."
    );
  }

  // all elements in the array are buffers, except the 8th one that is an
  // AccessListBuffer (an array of AccessListBufferItems)
  for (const [i, value] of values.entries()) {
    if (i === 7) {
      if (!Array.isArray(value)) {
        // we could check more things to assert that it's an AccessListBuffer,
        // but we're assuming that just checking if it's an array is enough
        throw new InvalidArgumentsError(
          `Invalid deserialized tx. Expected a AccessListBuffer in position ${...
function replacePragmaAbicoderDirectives = function replacePragmaAbicoderDirectives(file: string): string {
  return file.replaceAll(PRAGMA_DIRECTIVES_REGEX, (...groups) => {
    return `// Original pragma directive: ${removeUnnecessarySpaces(
      groups[1]
    )}`;
  });
}
function decodeEvmBytecode = function decodeEvmBytecode(contract, solcVersion, isDeployment, compilerBytecode, fileIdToSourceFile) {
    const libraryAddressPositions = (0, library_utils_1.getLibraryAddressPositions)(compilerBytecode);
    const immutableReferences = compilerBytecode.immutableReferences !== undefined
        ? Object.values(compilerBytecode.immutableReferences).reduce((previousValue, currentValue) => [...previousValue, ...currentValue], [])
        : [];
    const normalizedCode = (0, library_utils_1.normalizeCompilerOutputBytecode)(compilerBytecode.object, libraryAddressPositions);
    const instructions = (0, source_maps_1.decodeInstructions)(normalizedCode, compilerBytecode.sourceMap, fileIdToSourceFile, isDeployment);
    return new model_1.Bytecode(contract, isDeployment, normalizedCode, instructions, libraryAddressPositions, immutableReferences, solcVersion);
}
HardhatError.isHardhatErrorType(
          error,
          ERRORS.RESOLVER.FILE_NOT_FOUND
        ) ||
        HardhatError.isHardhatErrorType(
          error,
          ERRORS.RESOLVER.LIBRARY_FILE_NOT_FOUND
        )
const miningTimer = new MiningTimer_1.MiningTimer(this._config.intervalMining, async () => {
            try {
                await this.request({ method: "hardhat_intervalMine" });
            }
            catch (e) {
                console.error("Unexpected error calling hardhat_intervalMine:", e);
            }
        })
subtask(
  TASK_FLATTEN_GET_FLATTENED_SOURCE_AND_METADATA,
  "Returns all contracts and their dependencies flattened. Also return metadata about pragma directives and SPDX licenses"
)
  .addOptionalParam("files", undefined, undefined, types.any)
  .setAction(
    async (
      { files }: { files?: string[] },
      { run }
    ): Promise<[string, FlattenMetadata | null]> => {
      const dependencyGraph: DependencyGraph = await run(
        TASK_FLATTEN_GET_DEPENDENCY_GRAPH,
        { files }
      );

      let flattened = "";

      if (dependencyGraph.getResolvedFiles().length === 0) {
        return [flattened, null];
      }

      const packageJson = await getPackageJson();
      flattened += `// Sources flattened with hardhat v${packageJson.version} https://hardhat.org`;

      const sortedFiles = getSortedFiles(dependencyGraph);

      const [licenses, filesWithoutLicenses] = getLicensesInfo(sortedFiles);
      const [
        pragmaDirective,
        filesWithoutPragmaDirec...
function toRpcLogOutput = function toRpcLogOutput(log) {
    return {
        removed: false,
        address: (0, base_types_1.bufferToRpcData)(log.address),
        blockHash: log.blockHash !== null ? (0, base_types_1.bufferToRpcData)(log.blockHash) : null,
        blockNumber: log.blockNumber !== null ? (0, base_types_1.numberToRpcQuantity)(log.blockNumber) : null,
        data: (0, base_types_1.bufferToRpcData)(log.data),
        logIndex: log.logIndex !== null ? (0, base_types_1.numberToRpcQuantity)(log.logIndex) : null,
        transactionIndex: log.transactionIndex !== null
            ? (0, base_types_1.numberToRpcQuantity)(log.transactionIndex)
            : null,
        transactionHash: log.transactionHash !== null
            ? (0, base_types_1.bufferToRpcData)(log.transactionHash)
            : null,
        topics: log.topics.map((topic) => (0, base_types_1.bufferToRpcData)(topic)),
    };
}
throw new errors_1.HardhatError(errors_list_1.ERRORS.GENERAL.UNSUPPORTED_OPERATION, {
                operation: `Responding with "${actionResponse.action}" to the project initialization wizard`,
            });
function readPackageJson = function readPackageJson(packageName: string): PackageJson | undefined {
  try {
    const packageJsonPath = require.resolve(
      path.join(packageName, "package.json")
    );

    return require(packageJsonPath);
  } catch {
    return undefined;
  }
}
function getValidationErrors = function getValidationErrors(config) {
    const errors = [];
    // These can't be validated with io-ts
    if (config !== undefined && typeof config.networks === "object") {
        const hardhatNetwork = config.networks[constants_1.HARDHAT_NETWORK_NAME];
        if (hardhatNetwork !== undefined && typeof hardhatNetwork === "object") {
            if ("url" in hardhatNetwork) {
                errors.push(`HardhatConfig.networks.${constants_1.HARDHAT_NETWORK_NAME} can't have an url`);
            }
            // Validating the accounts with io-ts leads to very confusing errors messages
            const { accounts, ...configExceptAccounts } = hardhatNetwork;
            const netConfigResult = HardhatNetworkConfig.decode(configExceptAccounts);
            if (netConfigResult.isLeft()) {
                errors.push(getErrorMessage(`HardhatConfig.networks.${constants_1.HARDHAT_NETWORK_NAME}`, hardhatNetwork, "HardhatNetworkConfig"));
            }
            // manual validation o...
_tmp_2.push({
        name: "action",
        type: "select",
        message: "What do you want to do?",
        initial: 0,
        choices: Object.values(Action).map((a: Action) => {
          let message: string;
          if (isEsm) {
            if (a === Action.CREATE_EMPTY_HARDHAT_CONFIG_ACTION) {
              message = a.replace(".js", ".cjs");
            } else if (a === Action.CREATE_TYPESCRIPT_PROJECT_ACTION) {
              message = `${a} (not available for ESM projects)`;
            } else {
              message = a;
            }
          } else {
            message = a;
          }

          return {
            name: a,
            message,
            value: a,
          };
        }),
      })
_tmp_3.choices = Object.values(Action).map((a: Action) => {
          let message: string;
          if (isEsm) {
            if (a === Action.CREATE_EMPTY_HARDHAT_CONFIG_ACTION) {
              message = a.replace(".js", ".cjs");
            } else if (a === Action.CREATE_TYPESCRIPT_PROJECT_ACTION) {
              message = `${a} (not available for ESM projects)`;
            } else {
              message = a;
            }
          } else {
            message = a;
          }

          return {
            name: a,
            message,
            value: a,
          };
        })
function processModifierDefinitionAstNode = function processModifierDefinitionAstNode(
  modifierDefinitionNode: any,
  fileIdToSourceFile: Map<number, SourceFile>,
  contract: Contract,
  file: SourceFile
) {
  const functionLocation = astSrcToSourceLocation(
    modifierDefinitionNode.src,
    fileIdToSourceFile
  )!;

  const cf = new ContractFunction(
    modifierDefinitionNode.name,
    ContractFunctionType.MODIFIER,
    functionLocation,
    contract
  );

  contract.addLocalFunction(cf);
  file.addFunction(cf);
}
const artifactsEmittedPerJob = await pMap(compilationJobs, async (compilationJob, compilationJobIndex) => {
            const result = await run(task_names_1.TASK_COMPILE_SOLIDITY_COMPILE_JOB, {
                compilationJob,
                compilationJobs,
                compilationJobIndex,
                quiet,
            });
            return {
                compilationJob: result.compilationJob,
                artifactsEmittedPerFile: result.artifactsEmittedPerFile,
            };
        }, pMapOptions)
_tmp_14.NETWORK = {
        CONFIG_NOT_FOUND: {
            number: 100,
            message: "Network %network% doesn't exist",
            title: "Selected network doesn't exist",
            description: `You are trying to run Hardhat with a nonexistent network.

Read the [documentation](https://hardhat.org/hardhat-runner/docs/config#networks-configuration) to learn how to define custom networks.`,
            shouldBeReported: false,
        },
        INVALID_GLOBAL_CHAIN_ID: {
            number: 101,
            message: "Hardhat was set to use chain id %configChainId%, but connected to a chain with id %connectionChainId%.",
            title: "Connected to the wrong network",
            description: `Your config specifies a chain id for the network you are trying to use, but Hardhat detected a different chain id.

Please make sure you are setting your config correctly.`,
            shouldBeReported: false,
        },
        ETHSIGN_MISSING_DATA_PARAM: {
            number: 102,
           ...
_tmp_38.CONFIG_NOT_FOUND = {
            number: 100,
            message: "Network %network% doesn't exist",
            title: "Selected network doesn't exist",
            description: `You are trying to run Hardhat with a nonexistent network.

Read the [documentation](https://hardhat.org/hardhat-runner/docs/config#networks-configuration) to learn how to define custom networks.`,
            shouldBeReported: false,
        }
this._indent(() => {
            if (this._emptyHardhatMinedBlocksRangeStart !== undefined) {
                this._log(`Mined empty block range #${this._emptyHardhatMinedBlocksRangeStart} to #${blockNumber}`, { collapseHardhatMinedBlock: true, replaceLastLine: true });
            }
            else {
                this._emptyHardhatMinedBlocksRangeStart = blockNumber;
                this._log(`Mined empty block #${blockNumber}${baseFeePerGas !== undefined
                    ? ` with base fee ${baseFeePerGas.toString()}`
                    : ""}`, {
                    collapseHardhatMinedBlock: true,
                });
                return;
            }
        })
subtask(TASK_COMPILE_SOLIDITY_GET_COMPILATION_JOB_FOR_FILE)
  .addParam("dependencyGraph", undefined, undefined, types.any)
  .addParam("file", undefined, undefined, types.any)
  .addOptionalParam("solidityFilesCache", undefined, undefined, types.any)
  .setAction(
    async (
      {
        dependencyGraph,
        file,
      }: {
        dependencyGraph: taskTypes.DependencyGraph;
        file: taskTypes.ResolvedFile;
        solidityFilesCache?: SolidityFilesCache;
      },
      { config }
    ): Promise<CompilationJob | CompilationJobCreationError> => {
      return createCompilationJobFromFile(
        dependencyGraph,
        file,
        config.solidity
      );
    }
  )
_tmp_14.UNINITIALIZED_PROVIDER = {
      number: 21,
      message:
        "You tried to access an uninitialized provider. To initialize the provider, make sure you first call `.init()` or any method that hits a node like request, send or sendAsync.",
      title: "Uninitialized provider",
      description: `You tried to access an uninitialized provider. This is most likely caused by using the internal wrapped provider directly before using it to send a request or initializing it.
To initialize the provider, make sure you first call \`.init()\` or any method that hits a node like request, send or sendAsync.`,
      shouldBeReported: true,
    }
function saveCachedCompletionData = async function saveCachedCompletionData(
  projectId: string,
  completionData: CompletionData,
  mtimes: Mtimes
): Promise<void> {
  const cachedCompletionDataPath = await getCachedCompletionDataPath(projectId);

  await fs.outputJson(cachedCompletionDataPath, { completionData, mtimes });
}
<operator>.formatString("Solidity compiler is not configured. Version ", DEFAULT_SOLC_VERSION, " will be used by default. Add a 'solidity' entry to your configuration to suppress this warning.

Learn more about compiler configuration at https://hardhat.org/config
")
